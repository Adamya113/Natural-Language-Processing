{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30dd69d-26f3-4a02-9026-a661fde8fb3f",
   "metadata": {},
   "source": [
    "# Morphological Parser to accept/reject given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c968c6b2-8bc0-40fc-9550-13c2f0a9dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f27bc2c-f527-4d08-80b3-62e3810a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MorphologicalParser:\n",
    "    def __init__(self):\n",
    "        self.accepted_suffixes = [\"ing\", \"ed\", \"s\", \"ies\"]\n",
    "        self.accepted_prefixes = [\"un\", \"re\"]\n",
    "        self.lexicon = set(words.words())\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "   \n",
    "    def _is_spelled_correctly(self, word):\n",
    "            #Check if the word is spelled correctly\n",
    "            return word.lower() in self.lexicon\n",
    "\n",
    "    def _apply_capitalization(self, lemmatized_word, original_word):\n",
    "            # Apply capitalization based on the original word\n",
    "            if original_word.islower():\n",
    "                return lemmatized_word.lower()\n",
    "            elif original_word.isupper():\n",
    "                return lemmatized_word.upper()\n",
    "            elif original_word.istitle():\n",
    "                return lemmatized_word.capitalize()\n",
    "            else:\n",
    "                return lemmatized_word          \n",
    "    \n",
    "    def parse_words(self, word):\n",
    "        prefix = \"\"\n",
    "        suffix = \"\"\n",
    "        tokens = word_tokenize(word)\n",
    "\n",
    "        # Check if the word has an accepted prefix\n",
    "        for p in self.accepted_prefixes:\n",
    "            if tokens[0].startswith(p):\n",
    "                prefix = p\n",
    "                tokens[0] = tokens[0][len(p):]\n",
    "                break\n",
    "                \n",
    "        # Check if the word has an accepted suffix\n",
    "        for s in self.accepted_suffixes:\n",
    "            if tokens[-1].endswith(s):\n",
    "                suffix = s\n",
    "                tokens[-1] = tokens[-1][:-len(s)]\n",
    "                break\n",
    "\n",
    "        # Lemmatize the remaining words\n",
    "        lemmatized_word = self.lemmatizer.lemmatize(tokens[-1])\n",
    "\n",
    "        # Check if the lemmatized word is in the lexicon\n",
    "        if lemmatized_word.lower() in self.lexicon:\n",
    "            # Apply spelling rules\n",
    "            if self._is_spelled_correctly(lemmatized_word):\n",
    "                # Apply Orthographic rules\n",
    "                lemmatizef_word = self._apply_capitalization(lemmatized_word, word)\n",
    "\n",
    "                # Check if the remaining word is acceptable\n",
    "                if len(lemmatized_word) > 1:\n",
    "                    return f\"Accepted: ({prefix}-{lemmatized_word}-{suffix})\"\n",
    "        return \"Rejected\"\n",
    "\n",
    "             \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f982ebc-2dec-4eaf-9dd1-a30b17fae298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running:Rejected\n",
      "unhappy:Accepted: (un-happy-)\n",
      "restarted:Accepted: (re-start-ed)\n",
      "JUMPED:Rejected\n",
      "sit:Accepted: (-sit-)\n",
      "ed:Rejected\n",
      "unseen:Accepted: (un-seen-)\n",
      "ladys:Accepted: (-lady-s)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    nltk.download(\"punkt\")\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"words\")\n",
    "    parser = MorphologicalParser()\n",
    "\n",
    "    # Test some examples\n",
    "    words_to_test = [\"running\", \"unhappy\", \"restarted\", \"JUMPED\", \"sit\", \"ed\", \"unseen\", \"ladys\"]\n",
    "    for word in words_to_test:\n",
    "        result = parser.parse_words(word)\n",
    "        print(f\"{word}:{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88086c-8a2c-463c-bbc3-8ab2969f5abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
